\chapter{Spiking Neural Networks~(SNNs)}
\label{cha:bkg}
Biological studies have obtained increasing knowledge about facts, functions and anatomy of the brain.
At the cellular level, the central nervous system consists of two types of cells: neurons, the elementary processing units, and glial cells, the structural and metabolic supporters. 
Here we focus on the neurons, since they connect to each other forming the path from neural circuit and network to behaviour and cognition of the brain.
The human brains contains around a hundred of billions ($10^11$) such processing units, and three more orders of magnitudes connections, that are about $10^3$ connections per neuron.
The special structures of neurons enable them to send signals rapidly and precisely to other cells through these connections.


\section{Biological Neural Components}
\subsection{Neuron}
	\begin{figure}[bt]
	\centering
	\includegraphics[width=0.98\textwidth]{pics_snn/neuron2.png}
	\caption{Two neurons connected by synapses. 
		A neuron mainly is composed of three functional parts: dendrites, the soma, and the axon. (a) A pre-synaptic cell connects to its post-synaptic cell through synapses~\cite{reece2011campbell}, see (b)~\cite{reece2011campbell}, and the neural signal, action potential see (c)~\cite{hodgkin1939action}, propagates along the red arrows. }
	\label{Fig:neuron_basic}
\end{figure}
A typical neuron consists of three functional parts: dendrites, a cell body (soma), and an axon, see Figure~\ref{Fig:neuron_basic}(a).
The dendrites of a neuron receive stimuli from other neurons which the dendrites project to, and transmit the neural signal to the neuron's soma.
The soma is the cell body of the neuron where nucleus locates at, and functions like a non-linear processor that it triggers an output signal when accumulated total input exceeds some threshold.
The output signal initiates from the axon hillock where the axon emerges from the soma, and then propagated through the axon to other neurons.
Most of the neurons contains only one axon, but it may connects to many neurons by branching out axon terminals. 


The signal delivery from a neuron to another occurs at the junction between these two neurons, which is called a synapse, see Figure~\ref{Fig:neuron_basic}(b).
The neurons can be seen as a pre-synaptic cell which sends the signal, and a post-synaptic cell which receives.

%Spiking neuron models can be divided into two major categories \cite{gernstbook} based on their level of abstraction: The conductance models and the threshold models.
%The conductance models simulate a lower level on the ion channels, while the threshold models represent a higher level of neuron abstraction where the threshold voltage is fixed and the neuron fires once the membrane potential reaches it.
%
%In general, Conductance-Based models have been derived from the Nobel prize winners (1963) Hodgkin and Huxley, based on the experiments that they performed on the giant axon squid \cite{hhmodel}.
%Spikes arriving at a LIF neuron cause a temporary flow of current into (excitatory synapse) or out of (inhibitory synapse) the neuron, modelling the behaviour of synapses in biological neurons.
%The LIF neuron sums up this current over time, accumulating charge which gradually leaks away.
%If the membrane potential in the neuron reaches a certain threshold, it produces a spike and its charge is reset.
%LIF neurons have been extensively used in large spiking neural networks \cite{Delorme1999989} because of their ease of implementation and the low computational cost.


\subsection{Neuronal Signals}
The neuronal signals propagated among neurons are short electrical pulses, and Figure~\ref{Fig:neuron_basic}(c) shows the original recording of such a so-called action potential observed by using an squid giant axon.
A typical action potential, also known as a `spike', is of about 100~mV amplitude and lasts 1-2~ms.
Usually, there is a time period immediately after a spike that the neuron is unresponsive to any further stimulus.
This minimal time difference between two spikes of a single neuron is the absolute refractory period during which no spike can be generated.
While it is difficult but possible to fire a spike during the relative refractory period which immediately follows the absolute.

The size and duration of the spikes do not vary much among different species, and maintain the same form as the electrical pulses propagates along the axon.
Therefore, the form of an action potential carry little information, however it is the frequency and timing of the spikes that encode the messages.
A sequence of action potential generated by a single neuron is called a spike train, which can be seen as binary events against discrete time that `on' indicates a spiking event whereas `off' means none.
Information can be encoded in the frequency and timing of these binary events.


The rate coding model states that the spiking rate represents the intensity of a stimulus, e.g. as the stimulus becomes stronger, the frequency of the action potentials also increases.
An example of the tuning curve of a V1 simple cell responding to different stimulus orientation is shown in Figure~\ref{Fig:v1}.
As the stimulus becomes more suitable to the preferred orientation ($0^\circ$) of the neuron, the firing rate increases.

\begin{figure}[bt]
	\centering
	\includegraphics[width=0.8\textwidth]{pics_snn/v1.jpg}
	\caption{Example of rate coding: spike trains for different stimulus orientation (left) of a V1 simple cell of a cat, and the tuning curve (firing rate against stimulus orientation) of the neuron (right)~\cite{hubel1962receptive}.
	The square indicates the visual receptive field of the neuron, and a bar places at different orientation and moves orthogonally is the stimulus.
    As the stimulus becomes more suitable to the preferred orientation ($0^\circ$) of the neuron, the firing rate increases.}
	\label{Fig:v1}
\end{figure}

Rate coding works well when the stimulus is changing slowly and the observation time period is long enough to estimate the firing rate, however in practice the stimulus, e.g. visual sensory input, varies in a fast time scale and the neurons respond within a short reaction time.
Thus, temporal coding is a candidate method to compensate the encoding of fast changing stimulus.

Sound localisation requires temporal coding under precision of milliseconds, which is a good example of one of the temporal coding schemes, phase locking.
Figure~\ref{Fig:audio_fibre} shows phase-locked spike trains generated by Inner Hair Cells in the cochlea.
Phase locking forms the basis
of detecting time differences of binaural sound inputs.
\begin{figure}[bt]
	\centering
	\includegraphics[width=0.8\textwidth]{pics_snn/phaselocking.png}
	\caption{Example of temporal coding: phase-locked spike trains generated by Inner Hair Cells in the cochlea~\cite{liu2013modeling}.
	A sound source generates a sine wave of a certain frequency and conducts to two ears with a time difference and different amplitude due to the angle and distance of the sound source to the head.
	Two spike trains respond to different phases manipulated by a threshold of the sound waves.
	Sound localisation should be resolved by calculating the time difference and level difference of these sound waves which are encoded in the spike trains.
    }
	\label{Fig:audio_fibre}
\end{figure}

Time-to-first-spike encodes the information according to the intensity of a stimulus where a spike shortly after a reference signal indicates a strong stimulation and a later action potential is interpreted as a weaker input.
The tactile afferent information generated by forcing fingerprints from various directions are encoded in such a time-to-first-spike coding scheme~\cite{johansson2004first}.
Synchrony coding also can be found in the brain, where neurons represent the same ``concept'' always fire at the same time~\cite{von1994correlation}, for example in object recognition~\cite{gray1989stimulus}.
Established from the context of fast object recognition, rank-order coding was proposed that it discarded the precise time of spikes, but rather used the relative order of spikes among a group of neurons~\cite{gautrais1998rate}.


\subsection{Signal Transmission}
The spike, as an electrical signal, propagates to another neuron at the junction between these two neurons, a chemical synapse.
The axon terminal of a pre-synaptic neuron approaches very close (about 20~nm) to the dendrites (or cell body) of a  post-synaptic neuron.
The tiny space between neurons at a synapse is called the synaptic cleft, which is demonstrated in Figure~\ref{Fig:neuron_basic}(b).
At such a chemical synapse, the action potential generated by the pre-synaptic neuron triggers chemical neurotransmitter molecules to release into the synaptic cleft, and once the post-synaptic neuron detects these neurotransmitters it opens specific ion channels to drive electrical current flowing in.
Hence, synapses completes the transformation from electrical signal to chemical molecules and then back to ion influx.
The amount of neurotransmitters determines how strong the current flows into the post-synaptic neuron.
Thanks to the synaptic plasticity, changes of chemical synapses enables modulations on the synaptic efficacy, and forms the neuronal correlate of learning and memory.

\section{Modelling Spiking Neurons}
\label{sec:spike}
\subsection{Neural Dynamics}
%\subsubsection{Membrane Potential}
The effect of an ion influx on the post-synaptic neuron caused by spike transmission is the change of potential difference across the cell membrane.
This potential difference between the interior and exterior of the cell body, is called the \textbf{membrane potential}.
The membrane potential of a post-synaptic neuron stays at a \textbf{resting potential}, when no input comes.
As soon as a spike arrives, the membrane potential will be either depolarised (increased) or hyper-polarised (decreased) according to the type of synapses, and go back to the resting potential at last.
The behaviour of the membrane potential change caused by a single spike is called the post-synaptic potential (\textbf{PSP}). 
Thus, a spike transmitted by an excitatory synapse triggers an positive change of PSP, named excitatory post-synaptic potential (\textbf{EPSP}), see Figure~\ref{Fig:psp}(a), conversely the negative change, inhibitory post-synaptic potential (\textbf{IPSP}), is driven by inhibitory synaptic event and shown in Figure~\ref{Fig:psp}(b).


%\begin{figure}[tbh!]
%	\centering
%	\begin{subfigure}[t]{0.8\textwidth}
%		\includegraphics[width=\textwidth]{pics_snn/EI_PSP.JPG}
%		\caption{An electrode measures the \textbf{membrane potential} of a post-synaptic neuron which connected by two pre-synaptic neurons.}
%	\end{subfigure}\\
%	\begin{subfigure}[t]{0.8\textwidth}
%		\includegraphics[width=\textwidth]{pics_snn/psp.png}
%		\caption{\textbf{post-synaptic potential (PSP)} generated by spikes of its pre-synaptic neurons adds up to its \textbf{membrane potential} change. }
%	\end{subfigure}
%	\caption{A post-synaptic neuron $i$ receives input from two pre-synaptic neurons $j=1,2$.}
%	\label{Fig:neural_dynamics}
%\end{figure}

\begin{figure}[tb!]
	\centering
	\includegraphics[width=0.9\textwidth]{pics_snn/EI_PSP.JPG}
	\caption{Post-synaptic potential driven by a spike, where the red arrow represents a spike arriving at the neuron~\cite{marieb2007human}.}
	\label{Fig:psp}
\end{figure}

\begin{figure}[bt!]
	\centering
	\includegraphics[width=0.9\textwidth]{pics_snn/PSP.png}
	\caption{Summation of post-synaptic potentials~\cite{reece2011campbell}. 
		(a) Single EPSPs are usually not strong enough to trigger an action potential without summation. (b) Temporal summation of two EPSPs of the same synapse generates an action potential. (c) Spatial summation of two EPSPs of two synapse generates an action potential. (d) Spatial-temporal summation of both EPSP and IPSPs.
	}
	\label{Fig:psp_sum}
\end{figure}

Singe PSPs have an accumulated effect on the membrane potential both in temporal and spatial.
The accumulation performs simple summation of PSPs until the membrane potential reaches a \textbf{threshold}, that an action potential will be generated at the post-synaptic neuron.
Figure~\ref{Fig:psp_sum} illustrates temporal and spatial summations of PSPs under different circumstances.




\subsection{Neural Models}
The keys of modelling a spiking neuron are: 
\begin{itemize}
	\item to mathematically formalise the evolution of membrane potential;
	\item to states a mechanism of spike generation.
\end{itemize}

\subsubsection{Leaky Integrate-and-Fire}
The evolution of membrane potential can be simplified as a resistor–capacitor (RC) circuit which consists of a membrane capacitor, $C_m$ and a membrane resistance $R_m$, both driven by input current flow $I$, see Figure~\ref{Fig:rc}.
In the resting state without any input, the membrane potential $V$ stays at the same potential as the battery $V_{rest}$.
When current flows into the neuron, it will charge the capacitor $I_C(t)$ and flow through the resistance $I_R(t)$ to depolarise the membrane potential when the current stops the capacity charge will decay back to $V_{rest}$ by leaking through the resistance:
\begin{equation}
\begin{aligned}
	I(t) &= I_R(t) + I_C(t) \\
	&= \frac{V-V_{rest}}{R_m} + C_m \frac{\D u}{\D t}~~.
\end{aligned}
\end{equation}
The standard form of the LIF model can be written as:
\begin{equation}
\begin{aligned}
	\tau_m \frac{\D u}{\D t} &= -(V-V_{rest}) + R_m I(t)~, \textrm{~when~} V<V_{thresh}\\
	V &= V_{rest}~,  \textrm{~when~} V>=V_{thresh}
\end{aligned}
\end{equation}
where $V_{thresh}$ is the threshold of membrane potential and $\tau_m = C_m R_m$ is called the membrane time constant.

\begin{figure}[tb!]
	\centering
	\includegraphics[width=0.3\textwidth]{pics_snn/RC.png}
	\caption{Current flowing into a neuron functions like a resistor–capacitor (RC) circuit~\cite{gerstner2014neuronal}.}
	\label{Fig:rc}
\end{figure}

The simple Leaky Integrate-and-Fire~(LIF) model uses: (1) a linear differential equation to describe the evolution of membrane potential;
and (2) a threshold to generate a spike.

Applying LIF models to synaptic spike transmissions, we can use two types of synapses: current-based and conductance-based models.
Thus the synaptic efficacy $w$ determines either the input current intensity flowing through the synapse,
\begin{equation}
I(t) = w(t)~, \textrm{~current-based model;}
\end{equation}
or the electric conductance $g_{syn}$ of the ion channel,
\begin{equation}
	I(t) = g_{syn}(t) (V-E_{syn}) = w(t) (V-E_{syn})~, \textrm{~conductance-based model}
\end{equation}
where $E_{syn}$ indicates the reversal potential, a constant parameter of a neuron.

The current flow usually takes much longer than an action potential and decays over time, thus an simple exponential decay can be used to model the decaying synaptic efficacy:
\begin{equation}
w(t) = w_0 \exp^{-t/\tau_{syn}}~,
\end{equation}
assuming a spike is delivered at time $t=0$, the initial synaptic weight is set to $w_0$ and $\tau_{syn}$ is the synaptic time constant.

This thesis employs LIF neurons and current-based synapse model with exponentially-decaying post-synaptic current by default.

\subsubsection{Hodgkin-Huxley}
gari

\subsubsection{Izhikevich}
gari

\subsection{Synaptic Plasticity}
Jamie

\begin{figure}[bt]
	\centering
	\includegraphics[width=0.8\textwidth]{pics_snn/fig_stdp_orig.jpg}
	\caption{Synaptic Time Dependant Plasticity~\cite{gerstner2014neuronal}.}
	\label{Fig:STDP}
\end{figure}
%One of the key parameters of a neural network is the amount of influence each incoming spike has on a neuron.
The influence each incoming spike has on a post-synaptic neuron is modelled by assigning a `weight' to each synapse;
tuning on the weight scales the impact of a spike
arriving via that synapse.
Many learning models simulate the changes in weights over long periods of time observed within the brain.
The exact rules by which these weights are adjusted is the subject of much active research though most promising approaches attempt to learn from the relative timing \cite{pfister2006triplets} or rate \cite{bienenstock1982theory} of spikes arriving at a neuron.
As well as adjusting weights, some learning rules can also form entirely new connections between previously unconnected
neurons \cite{bamford2010synaptic}.

\section{Simulating Networks of Spiking Neurons}
\label{sec:snn_sim}
\subsection{Software Simulators}
clock driven

event driven

hybrid simulators Brian, Nest and Neuron

PyNN
\subsection{Neuromorphic Hardware}
Table from Steve
\subsection{Neuromorphic Standing-alone Systems}
Papers listed.
Vision and Auditory
\label{sec:morph}

